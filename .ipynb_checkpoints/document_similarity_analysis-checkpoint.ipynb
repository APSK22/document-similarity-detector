{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbb0dab",
   "metadata": {},
   "source": [
    "# Document Similarity Detector - Analysis Notebook\n",
    "\n",
    "This notebook demonstrates the implementation and analysis of various document similarity metrics used in Information Retrieval and Semantic Web applications.\n",
    "\n",
    "## Topics Covered:\n",
    "- **Vector Space Models** (TF-IDF)\n",
    "- **Cosine Similarity**\n",
    "- **Jaccard Index**\n",
    "- **Latent Semantic Analysis (LSA)**\n",
    "- **BERT Embeddings**\n",
    "- **IR Evaluation Metrics** (Precision, Recall, F1-Score)\n",
    "- **Embedding Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source venv/bin/activate\n",
    "pip install -r requirements-notebook.txt  # First time only\n",
    "jupyter notebook document_similarity_analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d50f6",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import re\n",
    "from collections import Counter\n",
    "from IPython.display import HTML, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcaaf7",
   "metadata": {},
   "source": [
    "## 2. Sample Documents\n",
    "\n",
    "Let's load our sample documents for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample documents\n",
    "with open('sample_doc1.txt', 'r') as f:\n",
    "    doc1 = f.read()\n",
    "\n",
    "with open('sample_doc2.txt', 'r') as f:\n",
    "    doc2 = f.read()\n",
    "\n",
    "print(\"Document 1:\")\n",
    "print(\"-\" * 80)\n",
    "print(doc1)\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "print(\"Document 2:\")\n",
    "print(\"-\" * 80)\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60863d",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing\n",
    "\n",
    "Clean and preprocess the documents for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Preprocess documents\n",
    "doc1_clean = preprocess_text(doc1)\n",
    "doc2_clean = preprocess_text(doc2)\n",
    "\n",
    "# Get word statistics\n",
    "words1 = doc1_clean.split()\n",
    "words2 = doc2_clean.split()\n",
    "\n",
    "print(f\"Document 1: {len(words1)} words, {len(set(words1))} unique words\")\n",
    "print(f\"Document 2: {len(words2)} words, {len(set(words2))} unique words\")\n",
    "print(f\"Common words: {len(set(words1).intersection(set(words2)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f54785",
   "metadata": {},
   "source": [
    "## 4. Similarity Metrics Implementation\n",
    "\n",
    "### 4.1 Jaccard Index (Set-Based Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(text1, text2):\n",
    "    \"\"\"Calculate Jaccard similarity coefficient.\"\"\"\n",
    "    words1 = set(preprocess_text(text1).split())\n",
    "    words2 = set(preprocess_text(text2).split())\n",
    "    \n",
    "    intersection = words1.intersection(words2)\n",
    "    union = words1.union(words2)\n",
    "    \n",
    "    jaccard = len(intersection) / len(union) if union else 0.0\n",
    "    \n",
    "    print(f\"Set 1 size: {len(words1)}\")\n",
    "    print(f\"Set 2 size: {len(words2)}\")\n",
    "    print(f\"Intersection: {len(intersection)}\")\n",
    "    print(f\"Union: {len(union)}\")\n",
    "    print(f\"Jaccard Index: {jaccard:.4f}\")\n",
    "    \n",
    "    return jaccard\n",
    "\n",
    "jaccard_score = jaccard_similarity(doc1, doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034360f",
   "metadata": {},
   "source": [
    "### 4.2 Cosine Similarity with TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "\n",
    "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary Size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
    "\n",
    "# Get TF-IDF vectors for collapsible display\n",
    "tfidf_doc1 = tfidf_matrix[0].toarray()[0]\n",
    "tfidf_doc2 = tfidf_matrix[1].toarray()[0]\n",
    "\n",
    "print(f\"\\nVector dimensions: {len(tfidf_doc1)}\")\n",
    "print(f\"Non-zero elements in Doc1: {np.count_nonzero(tfidf_doc1)}\")\n",
    "print(f\"Non-zero elements in Doc2: {np.count_nonzero(tfidf_doc2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077be812",
   "metadata": {},
   "source": [
    "#### Display TF-IDF Vectors in Collapsible Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collapsible_vector_display(vector, title, feature_names=None):\n",
    "    \"\"\"Create an HTML collapsible display for vectors.\"\"\"\n",
    "    \n",
    "    # Get top features\n",
    "    if feature_names:\n",
    "        top_indices = np.argsort(vector)[::-1][:20]\n",
    "        vector_data = [(feature_names[i], vector[i]) for i in top_indices if vector[i] > 0]\n",
    "    else:\n",
    "        vector_data = [(f\"Dim {i}\", val) for i, val in enumerate(vector) if val > 0][:20]\n",
    "    \n",
    "    # Create HTML table\n",
    "    rows = \"\"\n",
    "    for feature, value in vector_data:\n",
    "        bar_width = int(value * 100) if value <= 1 else int((value / max([v for _, v in vector_data])) * 100)\n",
    "        rows += f\"\"\"\n",
    "        <tr>\n",
    "            <td style=\"padding: 8px; color: #e6edf3;\">{feature}</td>\n",
    "            <td style=\"padding: 8px; color: #58a6ff; font-family: monospace;\">{value:.4f}</td>\n",
    "            <td style=\"padding: 8px;\">\n",
    "                <div style=\"background: #1f2937; border-radius: 4px; overflow: hidden;\">\n",
    "                    <div style=\"background: linear-gradient(90deg, #58a6ff, #3fb950); \n",
    "                                height: 20px; width: {bar_width}%;\"></div>\n",
    "                </div>\n",
    "            </td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <details style=\"background: #161b22; border: 1px solid #30363d; \n",
    "                    border-radius: 8px; padding: 16px; margin: 10px 0;\">\n",
    "        <summary style=\"cursor: pointer; font-size: 18px; font-weight: bold; \n",
    "                        color: #58a6ff; user-select: none;\">\n",
    "            {title} (Click to expand/collapse)\n",
    "        </summary>\n",
    "        <div style=\"margin-top: 16px;\">\n",
    "            <table style=\"width: 100%; border-collapse: collapse; color: #e6edf3;\">\n",
    "                <thead>\n",
    "                    <tr style=\"background: #0d1117; border-bottom: 2px solid #30363d;\">\n",
    "                        <th style=\"padding: 10px; text-align: left;\">Feature</th>\n",
    "                        <th style=\"padding: 10px; text-align: left;\">TF-IDF Score</th>\n",
    "                        <th style=\"padding: 10px; text-align: left;\">Weight</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "                    {rows}\n",
    "                </tbody>\n",
    "            </table>\n",
    "            <p style=\"margin-top: 16px; color: #8b949e; font-size: 14px;\">\n",
    "                Showing top {len(vector_data)} features out of {np.count_nonzero(vector)} non-zero elements\n",
    "            </p>\n",
    "        </div>\n",
    "    </details>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "# Display TF-IDF vectors\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "html_doc1 = create_collapsible_vector_display(tfidf_doc1, \"üìÑ Document 1 TF-IDF Vector\", feature_names)\n",
    "html_doc2 = create_collapsible_vector_display(tfidf_doc2, \"üìÑ Document 2 TF-IDF Vector\", feature_names)\n",
    "\n",
    "display(HTML(html_doc1))\n",
    "display(HTML(html_doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12405d2e",
   "metadata": {},
   "source": [
    "### 4.3 Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ac2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LSA using Truncated SVD\n",
    "n_components = min(50, tfidf_matrix.shape[1] - 1)\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "lsa_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Calculate similarity in LSA space\n",
    "lsa_sim = cosine_similarity(lsa_matrix[0:1], lsa_matrix[1:2])[0][0]\n",
    "\n",
    "print(f\"Original dimensions: {tfidf_matrix.shape[1]}\")\n",
    "print(f\"Reduced dimensions: {n_components}\")\n",
    "print(f\"Explained variance ratio: {svd.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"LSA Similarity: {lsa_sim:.4f}\")\n",
    "\n",
    "# Get LSA vectors\n",
    "lsa_doc1 = lsa_matrix[0]\n",
    "lsa_doc2 = lsa_matrix[1]\n",
    "\n",
    "# Display LSA vectors in collapsible format\n",
    "html_lsa1 = create_collapsible_vector_display(lsa_doc1, \"üîç Document 1 LSA Vector\")\n",
    "html_lsa2 = create_collapsible_vector_display(lsa_doc2, \"üîç Document 2 LSA Vector\")\n",
    "\n",
    "display(HTML(html_lsa1))\n",
    "display(HTML(html_lsa2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bac548",
   "metadata": {},
   "source": [
    "### 4.4 BERT Embeddings (Contextual Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "print(\"Loading BERT model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print(\"‚úì Model loaded!\")\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    \"\"\"Get BERT embeddings for text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use mean pooling\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Get BERT embeddings\n",
    "bert_emb1 = get_bert_embeddings(doc1)\n",
    "bert_emb2 = get_bert_embeddings(doc2)\n",
    "\n",
    "# Calculate similarity\n",
    "bert_sim = cosine_similarity(bert_emb1.reshape(1, -1), bert_emb2.reshape(1, -1))[0][0]\n",
    "\n",
    "print(f\"\\nBERT Embedding Dimensions: {len(bert_emb1)}\")\n",
    "print(f\"BERT Similarity: {bert_sim:.4f}\")\n",
    "\n",
    "# Display BERT embeddings in collapsible format\n",
    "html_bert1 = create_collapsible_vector_display(bert_emb1, \"ü§ñ Document 1 BERT Embedding\")\n",
    "html_bert2 = create_collapsible_vector_display(bert_emb2, \"ü§ñ Document 2 BERT Embedding\")\n",
    "\n",
    "display(HTML(html_bert1))\n",
    "display(HTML(html_bert2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46445577",
   "metadata": {},
   "source": [
    "## 5. Information Retrieval Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ir_metrics(text1, text2):\n",
    "    \"\"\"Calculate IR evaluation metrics.\"\"\"\n",
    "    words1 = set(preprocess_text(text1).split())\n",
    "    words2 = set(preprocess_text(text2).split())\n",
    "    \n",
    "    # Treating text2 as retrieved and text1 as relevant\n",
    "    true_positives = len(words1.intersection(words2))\n",
    "    \n",
    "    precision = true_positives / len(words2) if words2 else 0.0\n",
    "    recall = true_positives / len(words1) if words1 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "precision, recall, f1 = calculate_ir_metrics(doc1, doc2)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Visualize metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "values = [precision, recall, f1]\n",
    "colors = ['#58a6ff', '#3fb950', '#bb80ff']\n",
    "\n",
    "bars = ax.bar(metrics, values, color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Information Retrieval Evaluation Metrics', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{value:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfb230",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Similarity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2071228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "results = {\n",
    "    'Jaccard Index': jaccard_score,\n",
    "    'Cosine Similarity': cosine_sim,\n",
    "    'LSA Similarity': lsa_sim,\n",
    "    'BERT Similarity': bert_sim\n",
    "}\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "methods = list(results.keys())\n",
    "scores = list(results.values())\n",
    "colors_chart = ['#58a6ff', '#3fb950', '#bb80ff', '#f85149']\n",
    "\n",
    "bars = ax1.bar(methods, scores, color=colors_chart, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('Similarity Score', fontsize=12)\n",
    "ax1.set_title('Similarity Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=15)\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{score:.4f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(methods), endpoint=False).tolist()\n",
    "scores_radar = scores + [scores[0]]  # Complete the circle\n",
    "angles += angles[:1]\n",
    "\n",
    "ax2 = plt.subplot(122, projection='polar')\n",
    "ax2.plot(angles, scores_radar, 'o-', linewidth=2, color='#58a6ff', markersize=8)\n",
    "ax2.fill(angles, scores_radar, alpha=0.25, color='#3fb950')\n",
    "ax2.set_xticks(angles[:-1])\n",
    "ax2.set_xticklabels(methods, fontsize=10)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_title('Similarity Metrics Radar', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMILARITY ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for method, score in results.items():\n",
    "    print(f\"{method:20s}: {score:.4f}\")\n",
    "print(f\"\\n{'Average Similarity':20s}: {np.mean(scores):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f5975",
   "metadata": {},
   "source": [
    "## 7. Embedding Visualization with Collapsible Summary\n",
    "\n",
    "Display all embeddings in an organized, collapsible format for detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0228016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_embedding_display():\n",
    "    \"\"\"Create a comprehensive collapsible display of all embeddings.\"\"\"\n",
    "    \n",
    "    html = \"\"\"\n",
    "    <div style=\"background: #0d1117; padding: 20px; border-radius: 12px; \n",
    "                border: 2px solid #30363d; margin: 20px 0;\">\n",
    "        <h2 style=\"color: #58a6ff; text-align: center; margin-bottom: 20px;\">\n",
    "            üìä Complete Embedding Analysis Dashboard\n",
    "        </h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    # TF-IDF Section\n",
    "    html += \"\"\"\n",
    "    <div style=\"background: #161b22; border: 1px solid #30363d; \n",
    "                border-radius: 8px; padding: 16px; margin: 16px 0;\">\n",
    "        <h3 style=\"color: #3fb950; margin-bottom: 16px;\">üî§ TF-IDF Vectors</h3>\n",
    "    \"\"\"\n",
    "    html += create_collapsible_vector_display(tfidf_doc1, \"Document 1 TF-IDF\", feature_names)\n",
    "    html += create_collapsible_vector_display(tfidf_doc2, \"Document 2 TF-IDF\", feature_names)\n",
    "    html += f\"\"\"\n",
    "        <div style=\"margin-top: 16px; padding: 12px; background: #0d1117; \n",
    "                    border-radius: 6px; border-left: 4px solid #3fb950;\">\n",
    "            <strong style=\"color: #e6edf3;\">Cosine Similarity:</strong> \n",
    "            <span style=\"color: #58a6ff; font-size: 20px; font-weight: bold;\">{cosine_sim:.4f}</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # LSA Section\n",
    "    html += \"\"\"\n",
    "    <div style=\"background: #161b22; border: 1px solid #30363d; \n",
    "                border-radius: 8px; padding: 16px; margin: 16px 0;\">\n",
    "        <h3 style=\"color: #bb80ff; margin-bottom: 16px;\">üîç LSA Vectors (Dimensionality Reduced)</h3>\n",
    "    \"\"\"\n",
    "    html += create_collapsible_vector_display(lsa_doc1, \"Document 1 LSA\")\n",
    "    html += create_collapsible_vector_display(lsa_doc2, \"Document 2 LSA\")\n",
    "    html += f\"\"\"\n",
    "        <div style=\"margin-top: 16px; padding: 12px; background: #0d1117; \n",
    "                    border-radius: 6px; border-left: 4px solid #bb80ff;\">\n",
    "            <strong style=\"color: #e6edf3;\">LSA Similarity:</strong> \n",
    "            <span style=\"color: #58a6ff; font-size: 20px; font-weight: bold;\">{lsa_sim:.4f}</span>\n",
    "            <br>\n",
    "            <span style=\"color: #8b949e; font-size: 14px;\">\n",
    "                Reduced from {tfidf_matrix.shape[1]} to {n_components} dimensions\n",
    "            </span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # BERT Section\n",
    "    html += \"\"\"\n",
    "    <div style=\"background: #161b22; border: 1px solid #30363d; \n",
    "                border-radius: 8px; padding: 16px; margin: 16px 0;\">\n",
    "        <h3 style=\"color: #f85149; margin-bottom: 16px;\">ü§ñ BERT Embeddings (Contextual)</h3>\n",
    "    \"\"\"\n",
    "    html += create_collapsible_vector_display(bert_emb1, \"Document 1 BERT\")\n",
    "    html += create_collapsible_vector_display(bert_emb2, \"Document 2 BERT\")\n",
    "    html += f\"\"\"\n",
    "        <div style=\"margin-top: 16px; padding: 12px; background: #0d1117; \n",
    "                    border-radius: 6px; border-left: 4px solid #f85149;\">\n",
    "            <strong style=\"color: #e6edf3;\">BERT Similarity:</strong> \n",
    "            <span style=\"color: #58a6ff; font-size: 20px; font-weight: bold;\">{bert_sim:.4f}</span>\n",
    "            <br>\n",
    "            <span style=\"color: #8b949e; font-size: 14px;\">\n",
    "                {len(bert_emb1)}-dimensional contextual embeddings\n",
    "            </span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    html += \"</div>\"\n",
    "    return html\n",
    "\n",
    "# Display comprehensive dashboard\n",
    "display(HTML(create_comprehensive_embedding_display()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7dcaa1",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook demonstrated various document similarity techniques:\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Jaccard Index**: Simple set-based measure, good for exact word matches\n",
    "- **Cosine Similarity (TF-IDF)**: Considers word importance and frequency\n",
    "- **LSA**: Captures latent semantic relationships through dimensionality reduction\n",
    "- **BERT**: State-of-the-art contextual understanding using deep learning\n",
    "\n",
    "### Use Cases:\n",
    "- **Plagiarism Detection**: High similarity scores indicate potential copying\n",
    "- **Document Clustering**: Group similar documents together\n",
    "- **Search Engines**: Rank documents by relevance to queries\n",
    "- **Recommendation Systems**: Suggest similar content to users\n",
    "\n",
    "All embeddings are displayed in collapsible format for detailed analysis while maintaining a clean interface."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
